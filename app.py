import gradio as gr
import os
import tempfile
import zipfile
import shutil
import base64
from pdf2image import convert_from_path
from PIL import Image
from dotenv import load_dotenv

# ä½¿ç”¨ Google æ–°ç‰ˆ SDK
from google import genai
from google.genai import types

load_dotenv()

class NotebookLMTool:
    def __init__(self):
        self.api_key = os.getenv("GEMINI_API_KEY")
        self.client = None
        if self.api_key:
            self.client = genai.Client(api_key=self.api_key)

    def set_key(self, user_key):
        if user_key and user_key.strip():
            self.api_key = user_key.strip()
            self.client = genai.Client(api_key=self.api_key)
            return "âœ… API Key å·²æ›´æ–°ï¼"
        return "âš ï¸ Key ç„¡æ•ˆ"

    def process_pdf(self, pdf_file, progress=gr.Progress()):
        if not self.client:
            raise ValueError("è«‹å…ˆè¼¸å…¥ Google API Keyï¼")
        
        if pdf_file is None:
            return None, None, None

        # 1. æº–å‚™æš«å­˜ç›®éŒ„
        temp_dir = tempfile.mkdtemp()
        img_output_dir = os.path.join(temp_dir, "cleaned_images")
        os.makedirs(img_output_dir, exist_ok=True)
        
        # 2. PDF è½‰åœ–ç‰‡
        progress(0.1, desc="æ­£åœ¨å°‡ PDF è½‰ç‚ºåœ–ç‰‡...")
        try:
            images = convert_from_path(pdf_file)
        except Exception as e:
            raise ValueError(f"PDF è½‰æ›å¤±æ•— (è«‹ç¢ºèª packages.txt æœ‰åŠ å…¥ poppler-utils): {str(e)}")

        full_text = ""
        cleaned_images_paths = []
        gallery_preview = []

        # 3. é€é è™•ç†
        for i, img in enumerate(images):
            progress(0.1 + (0.8 * (i / len(images))), desc=f"AI æ­£åœ¨è™•ç†ç¬¬ {i+1}/{len(images)} é ...")
            
            # --- æ­¥é©Ÿ A: æå–æ–‡å­— (OCR) ---
            # ä½¿ç”¨æ¨™æº– Flash æ¨¡å‹è™•ç†æ–‡å­—ï¼Œé€Ÿåº¦æœ€å¿«
            try:
                resp_text = self.client.models.generate_content(
                    model="gemini-2.5-flash", 
                    contents=["Extract all text content from this slide strictly.", img]
                )
                page_content = resp_text.text if resp_text.text else "[No Text Found]"
            except Exception as e:
                page_content = f"[OCR Error: {e}]"
            
            full_text += f"=== Page {i+1} ===\n{page_content}\n\n"

            # --- æ­¥é©Ÿ B: åœ–ç‰‡å»å­— (Image Generation) ---
            # é—œéµä¿®æ”¹ï¼šå¿…é ˆä½¿ç”¨ 'gemini-2.0-flash-exp' ä¸”è©²æ¨¡å‹ç›®å‰æ‰æ”¯æ´ IMAGE è¼¸å‡º
            save_name = f"slide_{i+1:02d}.png"
            final_path = os.path.join(img_output_dir, save_name)
            
            try:
                resp_img = self.client.models.generate_content(
                    model="gemini-2.5-flash-image",  # âœ… ä¿®æ­£ï¼šä½¿ç”¨æ”¯æ´åœ–ç‰‡è¼¸å‡ºçš„å¯¦é©—æ¨¡å‹
                    contents=[
                        "Remove all text from this image. Fill the gaps using the surrounding background texture to make it look clean and natural. Output ONLY the image.", 
                        img
                    ],
                    config=types.GenerateContentConfig(
                        response_modalities=["IMAGE"] # âœ… ä¿®æ­£ï¼šæ˜ç¢ºå‘ŠçŸ¥éœ€è¦åœ–ç‰‡æ¨¡æ…‹
                    )
                )
                
                # è™•ç†åœ–ç‰‡å›å‚³ (è§£æ SDK å›æ‡‰)
                image_data = None
                
                # æª¢æŸ¥ inline_data (Base64)
                if hasattr(resp_img, 'parts') and resp_img.parts:
                    for part in resp_img.parts:
                        if part.inline_data:
                            image_data = part.inline_data.data
                            break
                
                # éƒ¨åˆ† SDK ç‰ˆæœ¬å¯èƒ½ç›´æ¥æ”¾åœ¨ bytes
                if image_data is None and hasattr(resp_img, 'bytes') and resp_img.bytes:
                    image_data = resp_img.bytes

                if image_data:
                    # å¦‚æœæ˜¯ Base64 å­—ä¸²ï¼Œéœ€è¦è§£ç¢¼
                    if isinstance(image_data, str): 
                        image_data = base64.b64decode(image_data)
                    
                    with open(final_path, "wb") as f:
                        f.write(image_data)
                    
                    cleaned_images_paths.append(final_path)
                    gallery_preview.append((final_path, f"Page {i+1} (Cleaned)"))
                    print(f"Page {i+1}: Image generated successfully.")
                else:
                    # å¤±æ•—å›é€€ï¼šä¿ç•™åŸåœ–ä¸¦æ¨™è¨˜
                    print(f"Page {i+1} Failed: No image data. Text: {resp_img.text if hasattr(resp_img, 'text') else 'Unknown'}")
                    img.save(final_path)
                    gallery_preview.append((final_path, f"Page {i+1} (Original - Gen Failed)"))

            except Exception as e:
                print(f"Page {i+1} Error: {str(e)}")
                img.save(final_path)
                gallery_preview.append((final_path, f"Page {i+1} (Original - Error)"))
        
        # 4. æ‰“åŒ…çµæœ
        progress(0.9, desc="æ­£åœ¨æ‰“åŒ… ZIP...")
        
        txt_path = os.path.join(temp_dir, "extracted_text.txt")
        with open(txt_path, "w", encoding="utf-8") as f:
            f.write(full_text)

        zip_path = os.path.join(temp_dir, "notebooklm_pack.zip")
        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zf:
            zf.write(txt_path, "content.txt")
            for img_path in cleaned_images_paths:
                zf.write(img_path, os.path.join("cleaned_slides", os.path.basename(img_path)))

        return zip_path, full_text, gallery_preview

# Init
tool = NotebookLMTool()

# --- Gradio UI ---
with gr.Blocks(title="NotebookLM Slide Decomposer", theme=gr.themes.Soft()) as demo:
    gr.Markdown("# ğŸ› ï¸ NotebookLM æŠ•å½±ç‰‡ PDF æ‹†è§£ç¥å™¨")
    gr.Markdown("""
    <div align="center">
    
    # ğŸ› ï¸ ä¸Šå‚³ NotebookLM æŠ•å½±ç‰‡ PDFï¼ŒAI è‡ªå‹•å¹«ä½ ï¼š**1. æŠ“å‡ºæ‰€æœ‰æ–‡å­—** | **2. é‡ç¹ªä¹¾æ·¨èƒŒæ™¯åœ–**  
    ğŸ‘‰ æ­¡è¿ Star [GitHub](https://github.com/Deep-Learning-101/) â­ è¦ºå¾—ä¸éŒ¯ ğŸ‘ˆ  
    <h3>ğŸ§  è£œè…¦å°ˆå€ï¼š<a href="https://deep-learning-101.github.io/" target="_blank">Deep Learning 101</a></h3>  
    
    | ğŸ”¥ æŠ€è¡“å‚³é€é–€ (Tech Stack) | ğŸ“š å¿…è®€å¿ƒæ³• (Must Read) |
    | :--- | :--- |
    | ğŸ¤– [**å¤§èªè¨€æ¨¡å‹ (LLM)**](https://deep-learning-101.github.io/Large-Language-Model) | ğŸ¹ [**ç­–ç•¥ç¯‡ï¼šä¼æ¥­å…¥é–€ç­–ç•¥**](https://deep-learning-101.github.io/Blog/AIBeginner) |
    | ğŸ“ [**è‡ªç„¶èªè¨€è™•ç† (NLP)**](https://deep-learning-101.github.io/Natural-Language-Processing) | ğŸ“Š [**è©•æ¸¬ç¯‡ï¼šè‡ºç£ LLM åˆ†æ**](https://deep-learning-101.github.io/Blog/TW-LLM-Benchmark) |
    | ğŸ‘ï¸ [**é›»è…¦è¦–è¦º (CV)**](https://deep-learning-101.github.io//Computer-Vision) | ğŸ› ï¸ [**å¯¦æˆ°ç¯‡ï¼šæ‰“é€ é«˜ç²¾æº– RAG**](https://deep-learning-101.github.io/RAG) |
    | ğŸ¤ [**èªéŸ³è™•ç† (Speech)**](https://deep-learning-101.github.io/Speech-Processing) | ğŸ•³ï¸ [**é¿å‘ç¯‡ï¼šAI Agent é–‹ç™¼é™·é˜±**](https://deep-learning-101.github.io/agent) |
    </div>
    """)
    
    with gr.Row():
        with gr.Column():
            api_input = gr.Textbox(label="Google API Key", type="password", placeholder="è²¼ä¸Šä½ çš„ Gemini API Key")
            btn_set_key = gr.Button("è¨­å®š Key")
            status_msg = gr.Markdown("")
            
            gr.Markdown("---")
            pdf_input = gr.File(label="ä¸Šå‚³ PDF")
            btn_process = gr.Button("ğŸš€ é–‹å§‹æ‹†è§£", variant="primary")
        
        with gr.Column():
            out_zip = gr.File(label="ğŸ“¦ ä¸‹è¼‰æ‡¶äººåŒ… (ZIP)")
            out_text = gr.Textbox(label="ğŸ“ æ–‡å­—å…§å®¹é è¦½", lines=8)
    
    gr.Markdown("### ğŸ–¼ï¸ è™•ç†çµæœé è¦½")
    out_gallery = gr.Gallery(columns=4)

    btn_set_key.click(tool.set_key, inputs=api_input, outputs=status_msg)
    
    btn_process.click(
        tool.process_pdf,
        inputs=[pdf_input],
        outputs=[out_zip, out_text, out_gallery]
    )

if __name__ == "__main__":
    demo.launch()
