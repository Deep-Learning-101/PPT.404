import gradio as gr
import os
import tempfile
import zipfile
import shutil
import base64
import json
import re
import concurrent.futures
import time
from pdf2image import convert_from_path
from PIL import Image
from dotenv import load_dotenv

# PPTX è™•ç†å¥—ä»¶
from pptx import Presentation
from pptx.util import Inches, Pt
from pptx.dml.color import RGBColor

# ä½¿ç”¨ Google æ–°ç‰ˆ SDK
from google import genai
from google.genai import types

load_dotenv()

class NotebookLMTool:
    def __init__(self):
        self.api_key = os.getenv("GEMINI_API_KEY")
        self.client = None
        if self.api_key:
            self.client = genai.Client(api_key=self.api_key)

    def set_key(self, user_key):
        if user_key and user_key.strip():
            self.api_key = user_key.strip()
            self.client = genai.Client(api_key=self.api_key)
            return "âœ… API Key å·²æ›´æ–°ï¼"
        return "âš ï¸ Key ç„¡æ•ˆ"

    def _extract_json(self, text):
        """å¼·åŒ–ç‰ˆ JSON æå–"""
        try:
            match = re.search(r"```json\s*(.*)\s*```", text, re.DOTALL)
            if match: return json.loads(match.group(1))
            match = re.search(r"\[\s*\{.*\}\s*\]", text, re.DOTALL)
            if match: return json.loads(match.group(0))
            return json.loads(text)
        except:
            return []

    # --- å–®é è™•ç†é‚è¼¯ (ç¨ç«‹å‡ºä¾†ä»¥ä¾¿å¹³è¡Œé‹ç®—) ---
    def process_single_page(self, page_index, img, img_output_dir):
        """è™•ç†å–®ä¸€é é¢çš„ï¼šå»å­—(èƒŒæ™¯) + æ–‡å­—åˆ†æ(Layout)"""
        print(f"ğŸš€ [Page {page_index+1}] é–‹å§‹è™•ç†...", flush=True)
        
        # çµæœå®¹å™¨
        result = {
            "index": page_index,
            "bg_path": None,
            "blocks": [],
            "log": "",
            "preview": None,
            "tokens_in": 0,
            "tokens_out": 0
        }

        save_name = f"slide_{page_index+1:02d}.png"
        final_bg_path = os.path.join(img_output_dir, save_name)
        bg_success = False

        # 1. èƒŒæ™¯å»å­— (Image Cleaning)
        try:
            clean_prompt = """
            Strictly remove all text, titles, text-boxes, and bullet points from this slide image.
            CRITICAL INSTRUCTION:
            1. Preserve the original background pattern, colors, logos, and non-text graphics EXACTLY as they are.
            2. Do NOT add any new objects, decorations, or hallucinations.
            3. Output ONLY the image.
            """
            
            # ä½¿ç”¨ 2.0-flash-exp é€²è¡Œç¹ªåœ–
            resp_img = self.client.models.generate_content(
                model="gemini-2.5-flash-image", 
                contents=[clean_prompt, img],
                config=types.GenerateContentConfig(response_modalities=["IMAGE"])
            )

            # Token çµ±è¨ˆ
            if resp_img.usage_metadata:
                result["tokens_in"] += resp_img.usage_metadata.prompt_token_count
                result["tokens_out"] += resp_img.usage_metadata.candidates_token_count

            # å­˜åœ–é‚è¼¯
            image_data = None
            if hasattr(resp_img, 'parts') and resp_img.parts:
                for part in resp_img.parts:
                    if part.inline_data: image_data = part.inline_data.data; break
            if image_data is None and hasattr(resp_img, 'bytes') and resp_img.bytes:
                image_data = resp_img.bytes

            if image_data:
                if isinstance(image_data, str): image_data = base64.b64decode(image_data)
                with open(final_bg_path, "wb") as f: f.write(image_data)
                bg_success = True
                result["bg_path"] = final_bg_path
                result["preview"] = (final_bg_path, f"Page {page_index+1} Cleaned")
            else:
                print(f"âš ï¸ [Page {page_index+1}] å»å­—å¤±æ•—: æœªå›å‚³åœ–ç‰‡", flush=True)

        except Exception as e:
            print(f"âŒ [Page {page_index+1}] Clean Error: {e}", flush=True)

        # å¤±æ•—å›é€€åŸåœ–
        if not bg_success:
            img.save(final_bg_path)
            result["bg_path"] = final_bg_path # ä»éœ€è·¯å¾‘çµ¦ PPT ä½¿ç”¨
            result["preview"] = (final_bg_path, f"Page {page_index+1} (Original)")
            result["log"] += f"[P{page_index+1}] Warning: Background cleaning failed.\n"

        # 2. æ–‡å­—èˆ‡ä½ˆå±€åˆ†æ (Layout Analysis)
        try:
            layout_prompt = """
            Analyze this slide. Return a JSON list of all text blocks.
            Each item: {"text": string, "box_2d": [ymin, xmin, ymax, xmax] (0-1000), "font_size": int, "color": hex, "is_bold": bool}
            """
            
            resp_layout = self.client.models.generate_content(
                model="gemini-2.5-flash", 
                contents=[layout_prompt, img],
                config=types.GenerateContentConfig(response_mime_type="application/json")
            )

            if resp_layout.usage_metadata:
                result["tokens_in"] += resp_layout.usage_metadata.prompt_token_count
                result["tokens_out"] += resp_layout.usage_metadata.candidates_token_count

            blocks = self._extract_json(resp_layout.text)
            result["blocks"] = blocks
            
            # ç´€éŒ„ Log
            for b in blocks:
                if b.get("text"): result["log"] += f"[P{page_index+1}] {b['text'][:20]}...\n"

        except Exception as e:
            print(f"âŒ [Page {page_index+1}] Layout Error: {e}", flush=True)
            result["log"] += f"[P{page_index+1}] Layout Analysis Failed.\n"

        print(f"âœ… [Page {page_index+1}] å®Œæˆï¼", flush=True)
        return result

    def process_pdf(self, pdf_file, progress=gr.Progress()):
        if not self.client:
            raise ValueError("è«‹å…ˆè¼¸å…¥ Google API Keyï¼")
        
        if pdf_file is None:
            return None, None, None, ""

        # çµ±è¨ˆæ•¸æ“š
        total_input_tokens = 0
        total_output_tokens = 0
        full_text_log = ""
        gallery_preview = []
        
        # 1. æº–å‚™ç’°å¢ƒ
        temp_dir = tempfile.mkdtemp()
        img_output_dir = os.path.join(temp_dir, "cleaned_images")
        os.makedirs(img_output_dir, exist_ok=True)
        
        # åˆå§‹åŒ– PPTX
        prs = Presentation()
        prs.slide_width = Inches(16)
        prs.slide_height = Inches(9)

        # 2. PDF è½‰åœ–ç‰‡ (é™ä½ DPI åŠ é€Ÿ)
        progress(0.1, desc="æ­£åœ¨å°‡ PDF è½‰ç‚ºåœ–ç‰‡ (DPI=150)...")
        try:
            # dpi=150 è¶³å¤ è¢å¹•æª¢è¦–ï¼Œä¸”å¤§å¹…æ¸›å°‘ä¸Šå‚³æ™‚é–“
            images = convert_from_path(pdf_file, dpi=150) 
        except Exception as e:
            raise ValueError(f"PDF è½‰æ›å¤±æ•—: {str(e)}")

        # 3. å¹³è¡Œè™•ç† (Parallel Execution)
        # æ ¹æ“š CPU æ ¸å¿ƒæ•¸æˆ– API é™åˆ¶è¨­å®š workersï¼Œå»ºè­° 3-5 é¿å… Rate Limit
        max_workers = 4 
        results_map = {} # ç”¨ä¾†å­˜çµæœï¼Œç¢ºä¿é †åºæ­£ç¢º

        progress(0.2, desc="ğŸš€ AI å¤šå·¥è™•ç†ä¸­ (å¯èƒ½éœ€è¦ç¨ç­‰)...")
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»å‹™
            future_to_page = {
                executor.submit(self.process_single_page, i, img, img_output_dir): i 
                for i, img in enumerate(images)
            }
            
            # ç­‰å¾…å®Œæˆ
            for future in concurrent.futures.as_completed(future_to_page):
                try:
                    res = future.result()
                    results_map[res["index"]] = res
                    # æ›´æ–° Token
                    total_input_tokens += res["tokens_in"]
                    total_output_tokens += res["tokens_out"]
                except Exception as exc:
                    print(f"Page processing generated an exception: {exc}")

        # 4. ä¾åºçµ„è£ PPTX (ç¢ºä¿é †åºæ­£ç¢º)
        progress(0.8, desc="æ­£åœ¨çµ„è£ PPTX...")
        
        cleaned_images_paths = [] # ç”¨æ–¼ ZIP
        
        for i in range(len(images)):
            if i not in results_map:
                print(f"Missing result for page {i}")
                continue
                
            res = results_map[i]
            
            # æ›´æ–° Log èˆ‡ Preview
            full_text_log += res["log"]
            if res["preview"]: gallery_preview.append(res["preview"])
            if res["bg_path"]: cleaned_images_paths.append(res["bg_path"])

            # å»ºç«‹ Slide
            slide = prs.slides.add_slide(prs.slide_layouts[6])
            
            # A. è²¼èƒŒæ™¯
            if res["bg_path"] and os.path.exists(res["bg_path"]):
                try:
                    slide.shapes.add_picture(res["bg_path"], 0, 0, width=prs.slide_width, height=prs.slide_height)
                except: pass
            
            # B. è²¼æ–‡å­—
            for block in res["blocks"]:
                text_content = block.get("text", "")
                if not text_content: continue
                
                # åº§æ¨™è½‰æ›
                box = block.get("box_2d", [0, 0, 100, 100])
                ymin, xmin, ymax, xmax = box
                left = Inches((xmin / 1000) * 16)
                top = Inches((ymin / 1000) * 9)
                width = Inches(((xmax - xmin) / 1000) * 16)
                height = Inches(((ymax - ymin) / 1000) * 9)
                
                textbox = slide.shapes.add_textbox(left, top, width, height)
                tf = textbox.text_frame
                tf.word_wrap = True
                p = tf.paragraphs[0]
                p.text = text_content
                
                try: p.font.size = Pt(int(block.get("font_size", 18)))
                except: p.font.size = Pt(18)
                p.font.bold = block.get("is_bold", False)
                try:
                    hex_c = block.get("color", "#000000").replace("#", "")
                    # å¦‚æœèƒŒæ™¯å»å­—å¤±æ•—ï¼ŒåŸåœ–èƒŒæ™¯å¯èƒ½å¾ˆè¤‡é›œï¼Œæ–‡å­—é¡è‰²å¯èƒ½éœ€è¦èª¿æ•´ (é€™è£¡æš«ä¸è™•ç†ï¼Œä¿æŒåŸè‰²)
                    p.font.color.rgb = RGBColor.from_string(hex_c)
                except: pass

        # 5. æ‰“åŒ…
        progress(0.9, desc="æ­£åœ¨æ‰“åŒ…æª”æ¡ˆ...")
        pptx_path = os.path.join(temp_dir, "restored_presentation.pptx")
        prs.save(pptx_path)

        txt_path = os.path.join(temp_dir, "content_log.txt")
        with open(txt_path, "w", encoding="utf-8") as f: f.write(full_text_log)

        zip_path = os.path.join(temp_dir, "notebooklm_restore_pack.zip")
        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zf:
            zf.write(pptx_path, "restored_slides.pptx")
            zf.write(txt_path, "content_log.txt")
            for img_path in cleaned_images_paths:
                zf.write(img_path, os.path.join("cleaned_backgrounds", os.path.basename(img_path)))

        token_stats = f"""
        ### ğŸ“Š Token ç”¨é‡çµ±è¨ˆ
        - **ç¸½è¼¸å…¥:** {total_input_tokens:,}
        - **ç¸½è¼¸å‡º:** {total_output_tokens:,}
        - **ç¸½è¨ˆæ¶ˆè€—:** {total_input_tokens + total_output_tokens:,}
        """

        return zip_path, pptx_path, gallery_preview, token_stats

# Init
tool = NotebookLMTool()

# --- Gradio UI ---
with gr.Blocks(title="NotebookLM Slide Restorerï¼ŒPPT.404", theme=gr.themes.Soft()) as demo:
    gr.Markdown("# ğŸ› ï¸ NotebookLM æŠ•å½±ç‰‡ PDF é‚„åŸç¥å™¨ (PPT.404)")
    gr.Markdown("""
    <div align="center">
    
    # ğŸª„ ä¸Šå‚³ PDFï¼ŒAI è‡ªå‹•ï¼š**å»å­—èƒŒæ™¯** + **ç‰ˆé¢åˆ†æ** + **åˆæˆå¯ç·¨è¼¯ PPTX**
    ğŸ‘‰ æ­¡è¿ Star [GitHub](https://github.com/Deep-Learning-101/) â­ è¦ºå¾—ä¸éŒ¯ ğŸ‘ˆ  
    
    <h3>ğŸ§  è£œè…¦å°ˆå€ï¼š<a href="https://deep-learning-101.github.io/" target="_blank">Deep Learning 101</a></h3>  
    
    | ğŸ”¥ æŠ€è¡“å‚³é€é–€ (Tech Stack) | ğŸ“š å¿…è®€å¿ƒæ³• (Must Read) |
    | :--- | :--- |
    | ğŸ¤– [**å¤§èªè¨€æ¨¡å‹ (LLM)**](https://deep-learning-101.github.io/Large-Language-Model) | ğŸ¹ [**ç­–ç•¥ç¯‡ï¼šä¼æ¥­å…¥é–€ç­–ç•¥**](https://deep-learning-101.github.io/Blog/AIBeginner) |
    | ğŸ“ [**è‡ªç„¶èªè¨€è™•ç† (NLP)**](https://deep-learning-101.github.io/Natural-Language-Processing) | ğŸ“Š [**è©•æ¸¬ç¯‡ï¼šè‡ºç£ LLM åˆ†æ**](https://deep-learning-101.github.io/Blog/TW-LLM-Benchmark) |
    | ğŸ‘ï¸ [**é›»è…¦è¦–è¦º (CV)**](https://deep-learning-101.github.io//Computer-Vision) | ğŸ› ï¸ [**å¯¦æˆ°ç¯‡ï¼šæ‰“é€ é«˜ç²¾æº– RAG**](https://deep-learning-101.github.io/RAG) |
    | ğŸ¤ [**èªéŸ³è™•ç† (Speech)**](https://deep-learning-101.github.io/Speech-Processing) | ğŸ•³ï¸ [**é¿å‘ç¯‡ï¼šAI Agent é–‹ç™¼é™·é˜±**](https://deep-learning-101.github.io/agent) |
    </div>
    """)
    
    with gr.Row():
        with gr.Column():
            api_input = gr.Textbox(label="Google API Key", type="password", placeholder="è²¼ä¸Šä½ çš„ Gemini API Key")
            btn_set_key = gr.Button("è¨­å®š Key")
            status_msg = gr.Markdown("")
            
            gr.Markdown("---")
            pdf_input = gr.File(label="ä¸Šå‚³ PDF")
            btn_process = gr.Button("ğŸš€ é–‹å§‹é‚„åŸ PPTX (å¹³è¡ŒåŠ é€Ÿç‰ˆ)", variant="primary")
        
        with gr.Column():
            out_zip = gr.File(label="ğŸ“¦ ä¸‹è¼‰å®Œæ•´åŒ…")
            out_pptx = gr.File(label="ğŸ“Š ç›´æ¥ä¸‹è¼‰ PPTX")
            out_tokens = gr.Markdown("### ğŸ“Š ç­‰å¾…è™•ç†...")
    
    gr.Markdown("### ğŸ–¼ï¸ èƒŒæ™¯å»å­—æ•ˆæœé è¦½")
    out_gallery = gr.Gallery(columns=4)

    btn_set_key.click(tool.set_key, inputs=api_input, outputs=status_msg)
    
    btn_process.click(
        tool.process_pdf,
        inputs=[pdf_input],
        outputs=[out_zip, out_pptx, out_gallery, out_tokens]
    )

if __name__ == "__main__":
    demo.launch()
